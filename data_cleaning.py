# -*- coding: utf-8 -*-
"""Data Cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11FRtgBjQJxBModQ6qL6H1YhtntkjGt1u
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

fish_data=pd.read_csv('/content/drive/MyDrive/FishStatPj/kmni/fish_landings.csv')
weather_data=pd.read_csv('/content/drive/MyDrive/FishStatPj/kmni/monthly_weather_data_malaysia.csv')

fish_data.head()

weather_data.head()

"""## Data Ingestion, Initial Exploration, and Preprocessing

This section details the initial steps taken to prepare the raw fish landings and weather data for subsequent predictive modeling. This phase encompasses data ingestion, initial exploratory data analysis to understand data characteristics, and comprehensive preprocessing steps to clean, standardize, and integrate the two disparate datasets into a unified and usable format.

### 1. Data Overview Before Preprocessing

**A. Fish Landings Data (`fish_data`)**

*   **Source**: Raw fish landings data was obtained from `fish_landings.csv`.
*   **Key Columns**: Initially, the dataset comprised columns such as `date`, `coast`, `state`, and `landings`.
*   **Date Format**: The `date` column was present as a string in 'YYYY-MM-DD' format, requiring conversion to datetime objects for time-series analysis.
*   **States**: The `state` column contained both specific Malaysian states (e.g., 'Perlis', 'Kedah', 'Johor') and aggregated entries like 'Malaysia' and 'All States'. These aggregated entries needed to be handled to focus on state-specific analyses.
*   **Timeframe**: The `fish_data` covered monthly landings from January 2018 to December 2023.

**B. Monthly Weather Data (`weather_data`)**

*   **Source**: Monthly weather metrics were sourced from `monthly_weather_data_malaysia.csv`.
*   **Key Columns**: This dataset included `year_month`, `place`, `city`, `state`, and a range of environmental variables such as `temperature`, `pressure`, `dew_point`, `humidity`, `wind_speed`, `gust`, `wind_chill`, `uv_index`, `feels_like_temperature`, `visibility`, and `pollutant_value`.
*   **State Naming Inconsistencies**: Initial exploration revealed minor inconsistencies in state naming; specifically, 'Labuan' in the weather data needed to be mapped to 'W.P. Labuan' to align with the fish landings data.
*   **Missing Values**: Several weather-related columns were observed to contain missing values, necessitating imputation strategies.
*   **Timeframe**: The `weather_data` spanned from August 1996 onwards, providing ample overlap with the fish landings data for correlation analysis.

### 2. Data Preprocessing Steps

The following sequential steps were performed to clean, standardize, and integrate the `fish_data` and `weather_data`:

1.  **Date Standardization and Feature Creation in `fish_data`**: The `date` column in `fish_data` was converted to `datetime` objects. A new column, `year_month`, was then extracted in 'YYYY-MM' string format from the `date` column. This `year_month` column served as a consistent temporal key for monthly aggregation and subsequent merging.

2.  **State Harmonization and Filtering**: To ensure consistency across datasets, a state mapping was applied to `weather_data`, converting 'Labuan' to 'W.P. Labuan'. Both `fish_data` and `weather_data` were then filtered to include only specific Malaysian states, excluding aggregated entries like 'Malaysia' and 'All States' from `fish_data` that did not represent individual state data.

3.  **Monthly Aggregation of Datasets**:
    *   The filtered `weather_data` was grouped by `state` and `year_month`, and the mean of all numerical weather features was calculated. This provided average monthly weather conditions for each state.
    *   Concurrently, the filtered `fish_data` was grouped by `state` and `year_month`, and the `landings` were summed to obtain total monthly fish landings per state.

4.  **Dataset Merging**: The aggregated `fish_data` (now `fish_agg`) and `weather_data` (now `weather_agg`) were merged into a new DataFrame, `final_df`. This merge was performed using a `left` join on the `state` and `year_month` columns, ensuring that all monthly fish landings entries were retained and matched with their corresponding monthly average weather data.

5.  **Missing Value Imputation**: Missing values (NaNs) in the weather-related columns within `final_df` were addressed through a two-step imputation strategy:
    *   **Linear Interpolation**: For all weather-related numerical columns (e.g., `temperature`, `pressure`, `gust`, etc.), linear interpolation was applied. This method filled missing values by estimating them based on the values of adjacent data points, performed independently for each `state` to account for regional variations.
    *   **State-wise Mean Imputation**: Following linear interpolation, any remaining NaNs (which could occur at the beginning or end of a state's time series) were replaced with the mean value of their respective column for that specific `state`. This ensured complete data for all states.
    *   **Overall Mean Imputation for Visibility**: Any residual missing values in the `visibility` column, after the state-wise imputation, were filled with the overall mean of the `visibility` column across the entire `final_df`. The `final_df.info()` output confirmed the successful imputation of all numerical columns, yielding a complete dataset.

### 3. Data Overview After Preprocessing

Upon completion of the preprocessing steps, the `final_df` emerged as a clean, integrated, and standardized dataset ready for further analysis and modeling. The key characteristics of the processed data are:

*   **Dimensions**: The `final_df` consists of 1008 rows and 14 columns, representing monthly records for various Malaysian states.
*   **Columns**: The dataset now includes `state`, `year_month`, `landings` (total monthly landings), and 10 weather-related features (`temperature`, `pressure`, `dew_point`, `humidity`, `wind_speed`, `gust`, `wind_chill`, `uv_index`, `feels_like_temperature`, `visibility`, `pollutant_value`).
*   **Completeness**: All numerical columns have been successfully imputed, ensuring no missing values remain. This was verified by `final_df.info()` which showed 1008 non-null counts for all columns.
*   **Consistency**: The `year_month` column is uniformly formatted as 'YYYY-MM' strings, providing a consistent time index for time-series analysis.
*   **Aggregation Level**: Data is aggregated at a monthly, state-specific level, allowing for direct investigation into the relationship between monthly weather conditions and fish landings in each state.

This prepared dataset is now suitable for exploratory data analysis (EDA) and subsequent predictive modeling, which will be detailed in the following sections or notebooks.
"""

fish_data['date'].unique()

fish_data['state'].unique()

weather_data['state'].unique()

import pandas as pd

fish_data['date'] = pd.to_datetime(fish_data['date'])
fish_data['year_month'] = fish_data['date'].dt.to_period('M').astype(str)

state_map = {
    'Labuan': 'W.P. Labuan'
}
weather_data['state'] = weather_data['state'].replace(state_map)

valid_states = [s for s in fish_data['state'].unique() if s not in {'Malaysia', 'All States'}]

# Filter weather data
weather_filtered = weather_data[weather_data['state'].isin(valid_states)].copy()

weather_agg = (
    weather_filtered
    .groupby(['state', 'year_month'], as_index=False)
    .mean(numeric_only=True)
)

fish_filtered = fish_data[
    fish_data['state'].isin(valid_states)
].copy()

fish_agg = (
    fish_filtered
    .groupby(['state', 'year_month'], as_index=False)
    .sum(numeric_only=True)  # sum landings
)

final_df = fish_agg.merge(
    weather_agg,
    on=['state', 'year_month'],
    how='left'
)

final_df

final_df.isnull().sum()

cols = ['temperature','pressure','dew_point','humidity','wind_speed','gust',
        'wind_chill','uv_index','feels_like_temperature','visibility','pollutant_value']

# Sort by state and year_month first
final_df = final_df.sort_values(['state','year_month'])

# Apply linear interpolation per state
for col in cols:
    final_df[col] = final_df.groupby('state')[col].transform(lambda x: x.interpolate(method='linear'))
for col in cols:
    final_df[col] = final_df.groupby('state')[col].transform(lambda x: x.interpolate(method='linear').fillna(x.mean()))

overall_mean = final_df['visibility'].mean(skipna=True)
final_df['visibility'] = final_df['visibility'].fillna(overall_mean)

final_df.info()

final_df.to_csv('/content/drive/MyDrive/FishStatPj/kmni/processed_data.csv',index=False)

final_df.head(5)